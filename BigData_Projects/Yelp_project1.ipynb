{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Description of Data\n",
    "\n",
    "The Yelp dataset is downloaded from Kaggle website. In total, there are 5,200,000 user reviews, information on 174,000 business. we will focus on two tables which are business table and review table. Attributes of business table are as following:\n",
    "\n",
    "- business_id: ID of the business\n",
    "- name: name of the business\n",
    "- neighborhood\n",
    "- address: address of the business\n",
    "- city: city of the business\n",
    "- state: state of the business\n",
    "- postal_code: postal code of the business\n",
    "- latitude: latitude of the business\n",
    "\n",
    "- longitude: longitude of the business\n",
    "- stars: average rating of the business\n",
    "- review_count: number of reviews received\n",
    "- is_open: 1 if the business is open, 0 therwise\n",
    "- categories: multiple categories of the business\n",
    "\n",
    "### Attribues of review table are as following:\n",
    "\n",
    "- review_id: ID of the review\n",
    "- user_id: ID of the user\n",
    "- business_id: ID of the business\n",
    "- stars: ratings of the business\n",
    "- date: review date\n",
    "- text: review from the user\n",
    "- useful: number of users who vote a review as usefull\n",
    "- funny: number of users who vote a review as funny\n",
    "- cool: number of users who vote a review as cool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tasks carried out on datasets:-\n",
    "\n",
    "###### Out of 7 csv data files, I chose to work on 2 of them\n",
    "- yelp_business.csv size: 30MB\n",
    "- yelp_review.csv   size:3.53GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '/usr/hdp/current/spark2-client/python')\n",
    "sys.path.insert(0, '/usr/hdp/current/spark2-client/python/lib/py4j-0.10.7-src.zip')\n",
    "\n",
    "os.environ['SPARK_HOME'] = '/usr/hdp/current/spark2-client/'\n",
    "os.environ['SPARK_CONF_DIR'] = '/etc/spark2/conf'\n",
    "os.environ['PYSPARK_PYTHON'] = '/opt/anaconda3/bin/python'\n",
    "\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setMaster(\"yarn\")\n",
    "conf.set(\"spark.driver.memory\",\"1g\")\n",
    "conf.set(\"spark.executor.instances\", \"8\")\n",
    "conf.set(\"spark.executor.memory\",\"8g\")\n",
    "conf.set(\"spark.executor.cores\",\"5\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://clnode225.clemson.cloudlab.us:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1.3.0.1.0-187</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 items\r\n",
      "drwxr-xr-x   - PK922097 hadoop          0 2020-01-02 14:11 Yelp_data/.ipynb_checkpoints\r\n",
      "-rw-r--r--   3 PK922097 hadoop   31760674 2020-01-02 14:11 Yelp_data/yelp_business.csv\r\n",
      "-rw-r--r--   3 PK922097 hadoop   41377121 2020-01-02 14:11 Yelp_data/yelp_business_attributes.csv\r\n",
      "-rw-r--r--   3 PK922097 hadoop   13866351 2020-01-02 14:11 Yelp_data/yelp_business_hours.csv\r\n",
      "-rw-r--r--   3 PK922097 hadoop    5053126 2020-01-02 14:10 Yelp_data/yelp_checkin.csv\r\n",
      "-rw-r--r--   3 PK922097 hadoop 3791120545 2020-01-02 14:11 Yelp_data/yelp_review.csv\r\n",
      "-rw-r--r--   3 PK922097 hadoop  148085910 2020-01-02 14:11 Yelp_data/yelp_tip.csv\r\n",
      "-rw-r--r--   3 PK922097 hadoop 1363176944 2020-01-02 14:11 Yelp_data/yelp_user.csv\r\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls Yelp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = sc.textFile(\"Yelp_data/yelp_business.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f9cf047de50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use of sqlContext for eploring the data\n",
    "\n",
    "sqlContext = pyspark.SQLContext(sc)\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .load(\"Yelp_data/yelp_business.csv\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- neighborhood: string (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- postal_code: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- review_count: string (nullable = true)\n",
      " |-- is_open: double (nullable = true)\n",
      " |-- categories: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+--------------------+--------------+---------+-----------+----------+-----------+------------+------------+-------+--------------------+\n",
      "|         business_id|                name|neighborhood|             address|          city|    state|postal_code|  latitude|  longitude|       stars|review_count|is_open|          categories|\n",
      "+--------------------+--------------------+------------+--------------------+--------------+---------+-----------+----------+-----------+------------+------------+-------+--------------------+\n",
      "|FYWN1wneV18bWNgQj...|\"\"\"Dental by Desi...|        null| \"\"\"4855 E Warner Rd|     Ste B9\"\"\"|Ahwatukee|         AZ|     85044| 33.3306902|-111.9785992|         4.0|   22.0|                   1|\n",
      "|He-G7vWjzVUysIKrf...|\"\"\"Stephen Szabo ...|        null|\"\"\"3101 Washingto...|      McMurray|       PA|      15317|40.2916853|-80.1048999|         3.0|          11|    1.0|Hair Stylists;Hai...|\n",
      "|KQPW8lFf1y5BT2Mxi...|\"\"\"Western Motor ...|        null|  \"\"\"6025 N 27th Ave|      Ste 1\"\"\"|  Phoenix|         AZ|     85017| 33.5249025|-112.1153098|         1.5|   18.0|                   1|\n",
      "|8DShNS-LuFqpEWIp0...|\"\"\"Sports Authori...|        null|\"\"\"5000 Arizona M...|    Ste 435\"\"\"|    Tempe|         AZ|     85282| 33.3831468|-111.9647254|         3.0|    9.0|                   0|\n",
      "|PfOCPjBrlQAnz__NX...|\"\"\"Brick House Ta...|        null|  \"\"\"581 Howe Ave\"\"\"|Cuyahoga Falls|       OH|      44221|41.1195346|-81.4756898|         3.5|         116|    1.0|American (New);Ni...|\n",
      "+--------------------+--------------------+------------+--------------------+--------------+---------+-----------+----------+-----------+------------+------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id \n",
      " ===with null values:  0\n",
      "name \n",
      " ===with null values:  0\n",
      "neighborhood \n",
      " ===with null values:  104758\n",
      "address \n",
      " ===with null values:  1699\n",
      "city \n",
      " ===with null values:  97\n",
      "state \n",
      " ===with null values:  8\n",
      "postal_code \n",
      " ===with null values:  590\n",
      "latitude \n",
      " ===with null values:  28\n",
      "longitude \n",
      " ===with null values:  6\n",
      "stars \n",
      " ===with null values:  2\n",
      "review_count \n",
      " ===with null values:  0\n",
      "is_open \n",
      " ===with null values:  0\n",
      "categories \n",
      " ===with null values:  0\n"
     ]
    }
   ],
   "source": [
    "# Calculating null values in dataset\n",
    "\n",
    "for col in business.columns:\n",
    "    \n",
    "    print(col, \"\\n\", \"===with null values: \", business.filter(business[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eploring review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .load(\"Yelp_data/yelp_review.csv\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- stars: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: string (nullable = true)\n",
      " |-- funny: string (nullable = true)\n",
      " |-- cool: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "|           review_id|             user_id|         business_id|stars|      date|                text|useful|funny|cool|\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "|vkVSCC7xljjrAI4UG...|bv2nCi5Qv5vroFiqK...|AEx2SYEUJmTxVVB18...|    5|2016-05-28|Super simple plac...|  null| null|null|\n",
      "|Staff was very he...|                   0|                   0|    0|      null|                null|  null| null|null|\n",
      "|n6QzIUObkYshz4dz2...|bv2nCi5Qv5vroFiqK...|VR6GpWIda3SfvPC-l...|    5|2016-05-28|Small unassuming ...|  null| null|null|\n",
      "|We had their beef...|                null|                null| null|      null|                null|  null| null|null|\n",
      "|A bit outside of ...|                   0|                   0|    0|      null|                null|  null| null|null|\n",
      "+--------------------+--------------------+--------------------+-----+----------+--------------------+------+-----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review_id \n",
      " ====with null values: 203\n",
      "user_id \n",
      " ====with null values: 2079178\n",
      "business_id \n",
      " ====with null values: 3165175\n",
      "stars \n",
      " ====with null values: 3871240\n",
      "date \n",
      " ====with null values: 5329698\n",
      "text \n",
      " ====with null values: 6135851\n",
      "useful \n",
      " ====with null values: 8641595\n",
      "funny \n",
      " ====with null values: 8918581\n",
      "cool \n",
      " ====with null values: 9077133\n"
     ]
    }
   ],
   "source": [
    "# calculating null values in dataset\n",
    "\n",
    "for col in review.columns:\n",
    "    \n",
    "    print(col, \"\\n\", \"====with null values:\", review.filter(review[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASKS:-\n",
    "\n",
    "\n",
    "\n",
    "## 1. Find top 10 reviewed business \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Following result is before dropping the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do this task take review data which has rating(stars) more than 3\n",
    "review3star = review.filter('stars >3')\n",
    "grouped_review = review3star.groupby('business_id','stars').count()\n",
    "review_sort = grouped_review.sort('count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|         business_id|stars|count|\n",
      "+--------------------+-----+-----+\n",
      "|                   2|    4| 4620|\n",
      "|                   3|    4| 4441|\n",
      "|                   4|    4| 3791|\n",
      "|                   1|    4| 3789|\n",
      "|4JNXUYY8wbaaDmk3B...|    5| 3280|\n",
      "|                   0|    4| 2883|\n",
      "|RESDUcs7fIiihp38-...|    5| 2725|\n",
      "|4JNXUYY8wbaaDmk3B...|    4| 2576|\n",
      "|                   4|    5| 2508|\n",
      "|                   3|    5| 2499|\n",
      "|DkYS3arLOhA8si5uU...|    5| 2443|\n",
      "|                   5|    4| 2435|\n",
      "|hihud--QRriCYZw1z...|    5| 2280|\n",
      "|cYwJA2A6I12KNkm2r...|    5| 2198|\n",
      "|KskYqH1Bi7Z_61pH6...|    5| 2162|\n",
      "|                   2|    5| 2126|\n",
      "|                   5|    5| 2031|\n",
      "|K7lWdNUhCbcnEvI0N...|    4| 1913|\n",
      "|RESDUcs7fIiihp38-...|    4| 1899|\n",
      "|f4x1YBxkLrZg652xt...|    5| 1888|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_sort.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = review.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "business = business.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so take review data which has rating(stars) more than 3\n",
    "review_star_three = review.filter('stars >3')\n",
    "grouped_review = review_star_three.groupby('business_id','stars').count()\n",
    "review_sort = grouped_review.sort('count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-----+\n",
      "|         business_id|stars|count|\n",
      "+--------------------+-----+-----+\n",
      "|4JNXUYY8wbaaDmk3B...|    5| 1894|\n",
      "|hihud--QRriCYZw1z...|    5| 1848|\n",
      "|RESDUcs7fIiihp38-...|    5| 1397|\n",
      "|cYwJA2A6I12KNkm2r...|    5| 1294|\n",
      "|f4x1YBxkLrZg652xt...|    5| 1242|\n",
      "|4JNXUYY8wbaaDmk3B...|    4| 1242|\n",
      "|KskYqH1Bi7Z_61pH6...|    5| 1178|\n",
      "|3kdSl5mo9dWC4clrQ...|    5| 1160|\n",
      "|DkYS3arLOhA8si5uU...|    5| 1101|\n",
      "|fL-b760btOaGa85OJ...|    5| 1026|\n",
      "|faPVqws-x-5k2CQKD...|    5|  951|\n",
      "|iCQpiavjjPzJ5_3gP...|    5|  942|\n",
      "|K7lWdNUhCbcnEvI0N...|    5|  902|\n",
      "|mDR12Hafvr84ctpsV...|    5|  896|\n",
      "|VyVIneSU7XAWgMBll...|    5|  889|\n",
      "|RwMLuOkImBIqqYj4S...|    5|  856|\n",
      "|igHYkXZMLAc9UdV5V...|    5|  843|\n",
      "|f4x1YBxkLrZg652xt...|    4|  814|\n",
      "|RESDUcs7fIiihp38-...|    4|  813|\n",
      "|Xg5qEQiB-7L6kGJ5F...|    5|  807|\n",
      "+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_sort.show()\n",
    "\n",
    "# bit of clean data after dropping null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Top 10 categories with highest business count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split,explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+-----+\n",
      "|category                 |count|\n",
      "+-------------------------+-----+\n",
      "|1                        |12624|\n",
      "|0                        |2895 |\n",
      "|Food;Coffee & Tea        |452  |\n",
      "|Coffee & Tea;Food        |398  |\n",
      "|Restaurants;Pizza        |324  |\n",
      "|Restaurants;Chinese      |303  |\n",
      "|Pizza;Restaurants        |294  |\n",
      "|Chinese;Restaurants      |279  |\n",
      "|Beauty & Spas;Hair Salons|268  |\n",
      "|Restaurants;Italian      |266  |\n",
      "+-------------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category = business.select('categories')\n",
    "individual_category = category.select(explode(split('categories', ',')).alias('category'))\n",
    "grouped_category = individual_category.groupby('category').count()\n",
    "top_category = grouped_category.sort('count',ascending=False)\n",
    "top_category.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          categories|\n",
      "+--------------------+\n",
      "|                   1|\n",
      "|Bakeries;Bagels;Food|\n",
      "|Restaurants;Ameri...|\n",
      "|Italian;French;Re...|\n",
      "|   Food;Coffee & Tea|\n",
      "|Bars;Sports Bars;...|\n",
      "|Tiki Bars;Nightli...|\n",
      "|                   1|\n",
      "|Coffee & Tea;Food...|\n",
      "|Arts & Entertainm...|\n",
      "|Hair Salons;Blow ...|\n",
      "|                   1|\n",
      "|                   1|\n",
      "| Italian;Restaurants|\n",
      "|Hotels & Travel;C...|\n",
      "|Nightlife;Bars;Ba...|\n",
      "|                   1|\n",
      "|                   1|\n",
      "|                   1|\n",
      "|                   1|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "business.select(['categories']).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. To claculate average rating for each business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_avg = sqlContext.sql(\"\"\"\n",
    "SELECT business_id , round(avg(stars),4) AS avg_rating\n",
    "FROM y_reviews\n",
    "Group By business_id\n",
    "\"\"\")\n",
    "business_avg.show(truncate=True)\n",
    "business_avg.sort('avg_rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4.Top rating given by users to business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top rating given by users to business\n",
    "\n",
    "rating = business.select('stars')\n",
    "User_rating = rating.groupby('stars').count()\n",
    "User_rating_top = User_rating.sort('count',ascending=False)\n",
    "User_rating_top.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. Locations which have more businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = business.select('business_id','city')\n",
    "review_city = review.select('business_id')\n",
    "\n",
    "# merging two dataframes to get final result\n",
    "merge_city = locations.join(review_city,'business_id','inner')\n",
    "grouped_review_city = merge_city.groupby('city').count()\n",
    "most_reviewed_city = grouped_review_city.groupby('city').sum()\n",
    "most_reviewed_city.sort('sum(count)',ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \n",
    "          \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \n",
    "          \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \n",
    "          \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \n",
    "          \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_data= sqlContext.read.format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .load(\"yelp_business.csv\")\\\n",
    "    .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US_data = US_data.drop('neighborhood','latitude','longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = US_data.filter(col('state').isin(states)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = df.select('categories')\n",
    "individual_category = category.select(explode(split('categories', ',')).alias('category'))\n",
    "grouped_category = individual_category.groupby('category').count()\n",
    "top_category = grouped_category.sort('count',ascending=False)\n",
    "top_category.show(10,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = df.select('business_id','city')\n",
    "review_city = review.select('business_id')\n",
    "\n",
    "# merging two dataframes to get final result\n",
    "merge_city = locations.join(review_city,'business_id','inner')\n",
    "grouped_review_city = merge_city.groupby('city').count()\n",
    "most_reviewed_city = grouped_review_city.groupby('city').sum()\n",
    "most_reviewed_city.sort('sum(count)',ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
